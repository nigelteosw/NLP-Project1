{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ID', 'Resume_str', 'Resume_html', 'Category', 'Clean_Resume', 'skills',\n",
      "       'soft_skills'],\n",
      "      dtype='object')\n",
      "Index(['title', 'description', 'skills_desc', 'combined_skills_desc',\n",
      "       'Clean_JD', 'skills'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Load datasets\n",
    "resumes = pd.read_csv('data/Resume Dataset/Resume/Resume_With_Skills.csv')\n",
    "jobs = pd.read_csv('data/Linkedin Job Postings (2023-2024)/cleaned_JD_with_skills.csv')\n",
    "\n",
    "# print column names\n",
    "print(resumes.columns)\n",
    "print(jobs.columns)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "resumes[\"text\"] = (\n",
    "    resumes[\"Clean_Resume\"] + \" \" +\n",
    "    resumes[\"skills\"].fillna(\"\") + \" \" +\n",
    "    resumes[\"soft_skills\"].fillna(\"\")\n",
    ")\n",
    "\n",
    "jobs[\"text\"] = (\n",
    "    jobs[\"Clean_JD\"] + \" \" +\n",
    "    jobs[\"skills\"].fillna(\"\") + \" \" +\n",
    "    jobs[\"skills_desc\"].fillna(\"\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings_in_batches(text_list, batch_size=16):\n",
    "    all_embeddings = []\n",
    "    for i in range(0, len(text_list), batch_size):\n",
    "        batch = text_list[i:i+batch_size]\n",
    "        inputs = tokenizer(\n",
    "            batch,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "            padding=True,\n",
    "            max_length=128\n",
    "        )\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        batch_embeddings = outputs.last_hidden_state.mean(dim=1).detach().numpy()\n",
    "        all_embeddings.append(batch_embeddings)\n",
    "    return np.vstack(all_embeddings)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "resumes[\"text\"] = resumes[\"text\"].astype(str).fillna(\"\")\n",
    "jobs[\"text\"] = jobs[\"text\"].astype(str).fillna(\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute embeddings\n",
    "resume_embeddings = get_embeddings(resumes[\"text\"].tolist())\n",
    "job_embeddings = get_embeddings(jobs[\"text\"].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rank Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Job Matches:\n",
      "SAP Basis: 0.75\n",
      "Contract Specialist: 0.73\n",
      "Database Administrator Manager: 0.73\n",
      "Technical Architect: 0.73\n",
      "Technical Architect: 0.73\n",
      "Technical Architect: 0.73\n",
      "Scrum master: 0.73\n",
      "High Ticket Enrollment Coach (Sales position): 0.73\n",
      "Water Damage Restoration Labor Specialist: 0.72\n",
      "Construction Specialist Labor - Paint Drywall Carpentry: 0.72\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def rank_jobs(resume_text, job_embeddings, jobs, top_n=10):\n",
    "    # Embed the resume\n",
    "    resume_embedding = get_embeddings([resume_text])\n",
    "    \n",
    "    # Compute cosine similarity\n",
    "    similarities = cosine_similarity(resume_embedding, job_embeddings)\n",
    "    \n",
    "    # Get top N jobs\n",
    "    top_indices = similarities.argsort()[0][-top_n:][::-1]\n",
    "    top_scores = similarities[0, top_indices]\n",
    "    \n",
    "    return jobs.iloc[top_indices], top_scores\n",
    "\n",
    "# Example resume of a teacher\n",
    "resume_text = \"\"\"\n",
    "I am a teacher with 5 years of experience in a primary school. I have a passion for teaching and I love working with children. I have a bachelor's degree in education and I am certified to teach in the state of California. I have experience teaching math, science, and English. I am patient, caring, and dedicated to helping my students succeed.\n",
    "\"\"\"\n",
    "top_jobs, scores = rank_jobs(resume_text, job_embeddings, jobs)\n",
    "\n",
    "# Display results\n",
    "print(\"Top Job Matches:\")\n",
    "for job, score in zip(top_jobs[\"title\"], scores):\n",
    "    print(f\"{job}: {score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
