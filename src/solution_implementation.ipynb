{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn import functional as F\n",
    "from torch import nn, optim\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Resume_str', 'Category', 'skills', 'hard_skills', 'roles'], dtype='object')\n",
      "Index(['roles', 'combined_skills_desc', 'skills', 'hard_skills'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Load datasets\n",
    "resumes = pd.read_csv('data\\Resume Dataset\\Resume\\Resume_With_Skills_And_Roles.csv')\n",
    "jobs = pd.read_csv('data/Linkedin Job Postings (2023-2024)/cleaned_JD_with_skills.csv')\n",
    "\n",
    "# print column names\n",
    "print(resumes.columns)\n",
    "print(jobs.columns)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine text fields into a single column for TF-IDF processing\n",
    "resumes[\"text_features\"] = resumes[\"Resume_str\"]\n",
    "jobs[\"text_features\"] = jobs[\"combined_skills_desc\"]\n",
    "\n",
    "# Ensure skills and hard skills are in list format\n",
    "resumes[\"skills_list\"] = resumes[\"skills\"].str.split(\", \")\n",
    "jobs[\"skills_list\"] = jobs[\"skills\"].str.split(\", \")\n",
    "\n",
    "resumes[\"hard_skills_list\"] = resumes[\"hard_skills\"].str.split(\", \")\n",
    "jobs[\"hard_skills_list\"] = jobs[\"hard_skills\"].str.split(\", \")\n",
    "\n",
    "# Get job roles\n",
    "resumes[\"job_roles_list\"] = resumes[\"roles\"].str.split(\", \")\n",
    "jobs[\"job_roles_list\"] = jobs[\"roles\"].str.split(\", \")\n",
    "\n",
    "# Show the first 5 rows of the dataframe\n",
    "# print(resumes.head())\n",
    "# print(jobs.head())\n",
    "\n",
    "# Remove all unnecessary columns\n",
    "resumes = resumes[[\"text_features\", \"skills_list\", \"hard_skills_list\", \"job_roles_list\"]]\n",
    "jobs = jobs[[\"text_features\", \"skills_list\", \"hard_skills_list\", \"job_roles_list\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumes shape:  (2483, 4)\n",
      "Jobs shape:  (2439, 4)\n",
      "Resumes shape:  (2460, 4)\n",
      "Jobs shape:  (2439, 4)\n"
     ]
    }
   ],
   "source": [
    "# Get size of datasets\n",
    "print(\"Resumes shape: \", resumes.shape)\n",
    "print(\"Jobs shape: \", jobs.shape)\n",
    "\n",
    "# Remove nan values\n",
    "resumes = resumes.dropna()\n",
    "jobs = jobs.dropna()\n",
    "\n",
    "# Get size of datasets\n",
    "print(\"Resumes shape: \", resumes.shape)\n",
    "print(\"Jobs shape: \", jobs.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['text_features', 'skills_list', 'hard_skills_list', 'job_roles_list'], dtype='object')\n",
      "Index(['text_features', 'skills_list', 'hard_skills_list', 'job_roles_list'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Show column names\n",
    "print(resumes.columns)\n",
    "print(jobs.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Initialize tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized resumes shape:  torch.Size([2460, 128])\n",
      "Tokenized job descriptions shape:  torch.Size([2439, 128])\n"
     ]
    }
   ],
   "source": [
    "# Tokenize resumes\n",
    "resume_text_features = resumes[\"text_features\"].tolist()\n",
    "tokenized_resumes = tokenizer(\n",
    "    resume_text_features,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=128,  # Adjust max_length as needed\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "# Tokenize job descriptions\n",
    "jd_text_features = jobs[\"text_features\"].tolist()\n",
    "tokenized_jds = tokenizer(\n",
    "    jd_text_features,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=128,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "# Print sizes of tokenized resumes and job descriptions\n",
    "print(\"Tokenized resumes shape: \", tokenized_resumes[\"input_ids\"].shape)\n",
    "print(\"Tokenized job descriptions shape: \", tokenized_jds[\"input_ids\"].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Resumes shape: torch.Size([2460, 128])\n",
      "Tokenized Jobs shape: torch.Size([2439, 128])\n"
     ]
    }
   ],
   "source": [
    "tokenized_resumes_tensor = tokenized_resumes['input_ids']\n",
    "tokenized_jds_tensor = tokenized_jds['input_ids']\n",
    "\n",
    "print(f\"Tokenized Resumes shape: {tokenized_resumes_tensor.shape}\")  # Expect torch.Size([2460, 128])\n",
    "print(f\"Tokenized Jobs shape: {tokenized_jds_tensor.shape}\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "resumes[\"combined_skills\"] = resumes[\"skills_list\"].apply(lambda x: \" \".join(x)) + \" \" + resumes[\"hard_skills_list\"].apply(lambda x: \" \".join(x))\n",
    "jobs[\"combined_skills\"] = jobs[\"skills_list\"].apply(lambda x: \" \".join(x)) + \" \" + jobs[\"hard_skills_list\"].apply(lambda x: \" \".join(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=100)\n",
    "resume_skills_tfidf_sparse = tfidf.fit_transform(resumes[\"combined_skills\"])\n",
    "resume_skills_tfidf_dense = resume_skills_tfidf_sparse.toarray()  # Converts sparse to dense\n",
    "\n",
    "jd_skills_tfidf_sparse = tfidf.transform(jobs[\"combined_skills\"])\n",
    "jd_skills_tfidf_dense = jd_skills_tfidf_sparse.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anadu\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchvision\\datapoints\\__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "C:\\Users\\Anadu\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchvision\\transforms\\v2\\__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume roles embeddings shape: torch.Size([2460, 384])\n",
      "Job roles embeddings shape: torch.Size([2439, 384])\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Initialize the model\n",
    "embedder = SentenceTransformer('all-MiniLM-L6-v2')  # Lightweight and efficient model\n",
    "\n",
    "# Convert job roles list to sentences\n",
    "resumes[\"job_roles_str\"] = resumes[\"job_roles_list\"].apply(lambda roles: \" \".join(roles))\n",
    "jobs[\"job_roles_str\"] = jobs[\"job_roles_list\"].apply(lambda roles: \" \".join(roles))\n",
    "\n",
    "# Generate embeddings for job roles\n",
    "resume_roles_emb = embedder.encode(resumes[\"job_roles_str\"].tolist(), convert_to_tensor=True)\n",
    "jd_roles_emb = embedder.encode(jobs[\"job_roles_str\"].tolist(), convert_to_tensor=True)\n",
    "\n",
    "print(f\"Resume roles embeddings shape: {resume_roles_emb.shape}\")\n",
    "print(f\"Job roles embeddings shape: {jd_roles_emb.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_skills_tfidf = torch.tensor(resume_skills_tfidf_dense, dtype=torch.float32)\n",
    "jd_skills_tfidf = torch.tensor(jd_skills_tfidf_dense, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Resume Features shape: torch.Size([2460, 612])\n",
      "Combined JD Features shape: torch.Size([2439, 612])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anadu\\AppData\\Local\\Temp\\ipykernel_8084\\266499371.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  resume_skills_tfidf_tensor = torch.tensor(resume_skills_tfidf, dtype=torch.float32)\n",
      "C:\\Users\\Anadu\\AppData\\Local\\Temp\\ipykernel_8084\\266499371.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  job_skills_tfidf_tensor = torch.tensor(jd_skills_tfidf, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Convert TF-IDF features to tensors\n",
    "resume_skills_tfidf_tensor = torch.tensor(resume_skills_tfidf, dtype=torch.float32)\n",
    "job_skills_tfidf_tensor = torch.tensor(jd_skills_tfidf, dtype=torch.float32)\n",
    "\n",
    "# Concatenate tokenized text, TF-IDF features, and role embeddings\n",
    "resume_combined_features = torch.cat([tokenized_resumes_tensor, resume_skills_tfidf_tensor, resume_roles_emb], dim=1)\n",
    "jd_combined_features = torch.cat([tokenized_jds_tensor, job_skills_tfidf_tensor, jd_roles_emb], dim=1)\n",
    "\n",
    "print(f\"Combined Resume Features shape: {resume_combined_features.shape}\")  # Expect (2460, 612)\n",
    "print(f\"Combined JD Features shape: {jd_combined_features.shape}\")          # Expect (2439, 612)         # Expected: (2439, 128 + 100 + 384)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build two tower models and combine them with a simple MLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class ResumeJDDataset(Dataset):\n",
    "    def __init__(self, resumes, jobs, num_negatives=1):\n",
    "        self.resumes = resumes\n",
    "        self.jobs = jobs\n",
    "        self.num_negatives = num_negatives  # Number of negative samples per positive pair\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.resumes)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Positive pair\n",
    "        resume = self.resumes[idx]\n",
    "        jd_positive = self.jobs[idx % len(self.jobs)]  # Matching positive JD\n",
    "        positive_label = 1\n",
    "\n",
    "        # Negative pairs\n",
    "        negative_indices = torch.randint(0, len(self.jobs), (self.num_negatives,))\n",
    "        jd_negatives = [self.jobs[i] for i in negative_indices]\n",
    "        negative_labels = [0] * self.num_negatives\n",
    "\n",
    "        # Combine positive and negative pairs\n",
    "        resume_batch = [resume] * (1 + self.num_negatives)  # Repeat the resume for all pairs\n",
    "        jd_batch = [jd_positive] + jd_negatives\n",
    "        labels = [positive_label] + negative_labels\n",
    "\n",
    "        return {\n",
    "            'resume_features': torch.stack(resume_batch),\n",
    "            'jd_features': torch.stack(jd_batch),\n",
    "            'label': torch.tensor(labels, dtype=torch.float32)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume Features Batch Shape: torch.Size([32, 3, 612])\n",
      "Job Features Batch Shape: torch.Size([32, 3, 612])\n",
      "Labels Batch Shape: torch.Size([32, 3])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Initialize the dataset\n",
    "num_negatives = 2  # Number of negative samples per positive pair\n",
    "train_dataset = ResumeJDDataset(\n",
    "    resumes=resume_combined_features,\n",
    "    jobs=jd_combined_features,\n",
    "    num_negatives=num_negatives\n",
    ")\n",
    "\n",
    "# Initialize the DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Verify the output of the DataLoader\n",
    "for batch in train_loader:\n",
    "    print(f\"Resume Features Batch Shape: {batch['resume_features'].shape}\")  # Expect (32, 1+num_negatives, 612)\n",
    "    print(f\"Job Features Batch Shape: {batch['jd_features'].shape}\")         # Expect (32, 1+num_negatives, 612)\n",
    "    print(f\"Labels Batch Shape: {batch['label'].shape}\")                    # Expect (32, 1+num_negatives)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class TwoTowerModel(nn.Module):\n",
    "    def __init__(self, input_dim=612, projection_dim=256):\n",
    "        super(TwoTowerModel, self).__init__()\n",
    "        \n",
    "        # Resume Tower\n",
    "        self.resume_tower = nn.Sequential(\n",
    "            nn.Linear(input_dim, projection_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(projection_dim, projection_dim)\n",
    "        )\n",
    "\n",
    "        # Job Description Tower\n",
    "        self.jd_tower = nn.Sequential(\n",
    "            nn.Linear(input_dim, projection_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(projection_dim, projection_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, resume_features, jd_features):\n",
    "        # Pass features through respective towers\n",
    "        resume_proj = self.resume_tower(resume_features)\n",
    "        jd_proj = self.jd_tower(jd_features)\n",
    "        \n",
    "        return resume_proj, jd_proj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 0.0000\n",
      "Epoch 2/5, Loss: 0.0000\n",
      "Epoch 3/5, Loss: 0.0000\n",
      "Epoch 4/5, Loss: 0.0000\n",
      "Epoch 5/5, Loss: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Initialize model, loss function, and optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = TwoTowerModel(input_dim=612, projection_dim=256).to(device)\n",
    "criterion = nn.MSELoss()  # Regression loss on cosine similarity\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Training Loop\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        # Flatten dynamic pairs into a single batch\n",
    "        resume_features = batch['resume_features'].view(-1, batch['resume_features'].shape[-1]).to(device)\n",
    "        jd_features = batch['jd_features'].view(-1, batch['jd_features'].shape[-1]).to(device)\n",
    "        labels = batch['label'].view(-1).to(device)\n",
    "\n",
    "\n",
    "        # Forward pass through the model\n",
    "        resume_proj, jd_proj = model(resume_features, jd_features)\n",
    "\n",
    "        # Compute cosine similarity\n",
    "        similarity = torch.nn.functional.cosine_similarity(resume_proj, jd_proj, dim=-1)\n",
    "\n",
    "        # Calculate loss and backpropagate\n",
    "        loss = criterion(similarity, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Loss: {total_loss / len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rank Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
